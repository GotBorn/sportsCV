{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "testLaunch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUwzkb-OxNDZ"
      },
      "source": [
        "T4 - хорошо\n",
        "\n",
        "K80 - плохо"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmgXGWpKOjJ2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e4aab99-1528-4853-d4f4-25046faa678f"
      },
      "source": [
        "!nvidia-smi -L"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-60ea37c1-5c87-4e18-495d-b7dc67e2fbc2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95Bv6nYZ1lGU"
      },
      "source": [
        "Много импортов и определение функции infer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIEw46f3wYeY"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import shutil\n",
        "import os\n",
        "import random\n",
        "import zipfile\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import csv\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torchvision import transforms\n",
        "import torch.nn.functional as F\n",
        "import copy\n",
        "import tqdm\n",
        "import time\n",
        "from PIL import Image\n",
        "\n",
        "import albumentations\n",
        "from albumentations import pytorch as AT"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7_Wot_2wgeq"
      },
      "source": [
        "def SeedEverything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBkY5cDDwGUe"
      },
      "source": [
        "def infer(modelDataPath, datasetPath):\n",
        "    SeedEverything(41)\n",
        "\n",
        "    labelList = ['baseball', 'formula1', 'fencing', 'motogp', 'ice_hockey',# был ранее получен функцией GetCategoryList\n",
        "                 'wrestling', 'boxing', 'volleyball', 'cricket', 'basketball', 'wwe',\n",
        "                 'swimming', 'weight_lifting', 'gymnastics', 'tennis', 'kabaddi', 'badminton',\n",
        "                 'football', 'table_tennis', 'hockey', 'shooting', 'chess']\n",
        "\n",
        "    test_files = os.listdir(datasetPath)\n",
        "    print(\"Test set size: \", len(test_files))  # 1645\n",
        "    class SportsDataset(Dataset):\n",
        "        def __init__(self, file_list, dir, transform=None):\n",
        "            self.file_list = file_list\n",
        "            self.dir = dir\n",
        "            self.transform = transform\n",
        "\n",
        "        def __len__(self):\n",
        "            return len(self.file_list)\n",
        "\n",
        "        def __getitem__(self, idx):\n",
        "            image = cv2.imread(os.path.join(self.dir, self.file_list[idx]))\n",
        "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "            if self.transform:\n",
        "                augmented = self.transform(image=image)\n",
        "                image = augmented['image']\n",
        "\n",
        "            return image\n",
        "\n",
        "    img_size = 256\n",
        "\n",
        "    data_transforms_test = albumentations.Compose([\n",
        "        albumentations.Resize(img_size, img_size),\n",
        "        albumentations.Normalize(),\n",
        "        AT.ToTensor()\n",
        "    ])\n",
        "\n",
        "    test_set = SportsDataset(test_files, datasetPath, data_transforms_test)\n",
        "\n",
        "    testloader = torch.utils.data.DataLoader(test_set, batch_size=1,\n",
        "                                             num_workers=0, shuffle=False)\n",
        "\n",
        "    samples = next(iter(testloader))\n",
        "    plt.figure(figsize=(16, 24))\n",
        "    grid_imgs = torchvision.utils.make_grid(samples[:24])\n",
        "    np_grid_imgs = grid_imgs.numpy()\n",
        "    plt.imshow(np.transpose(np_grid_imgs, (1, 2, 0)))\n",
        "\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"Device: \", device)\n",
        "\n",
        "    model = torchvision.models.resnet152(pretrained=True, progress=True)\n",
        "    model.fc = nn.Linear(2048, 1024)\n",
        "    model.fc1 = nn.Linear(1024, 512)\n",
        "    model.fc2 = nn.Linear(512, 22)\n",
        "    model.load_state_dict(torch.load(modelDataPath))\n",
        "    model.eval()\n",
        "\n",
        "    model = model.to(device)\n",
        "\n",
        "    print(\"Classification started\")\n",
        "\n",
        "    model.eval()\n",
        "    f = open(\"output.csv\", \"w\")\n",
        "    with torch.no_grad():\n",
        "        for i, image in enumerate(testloader, 0):\n",
        "            image = image.to(device=device)\n",
        "            output = model(image)\n",
        "            _, predicted = torch.max(output.data, 1)\n",
        "            sample_fname = testloader.dataset.file_list[i]\n",
        "            line = datasetPath + \"\\\\\" + sample_fname + \",\" + str(labelList[predicted.item()]) + '\\n'\n",
        "            f.write(line)\n",
        "    f.close()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cH6_ZB1j1vAg"
      },
      "source": [
        "Подключение Google Drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qoQyTdPw3UC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "230cf197-8f1e-42f5-e5c8-d33805326f8d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4Zz-gH01zFn"
      },
      "source": [
        "Непосредственно запуск скрипта"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIgLS1OUwE1W"
      },
      "source": [
        "print(\"Введите полный путь до датасета (Например D:\\\\dataset):\")\n",
        "datasetPath = input()\n",
        "print(\"Введите полный путь до весов модели:\")\n",
        "modelDataPath = input()\n",
        "\n",
        "infer(modelDataPath, datasetPath)\n",
        "\n",
        "print(\"Результат находится в output.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}